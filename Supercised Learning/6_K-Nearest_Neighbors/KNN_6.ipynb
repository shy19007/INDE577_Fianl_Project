{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z8n6CKSgKVg"
      },
      "source": [
        "# **The k-Nearest Neighbors (KNN) Algorithm**\n",
        "\n",
        "## **Introduction**\n",
        "\n",
        "The k-Nearest Neighbors (KNN) algorithm is a highly regarded method within the realm of machine learning, known for its application in both classification and regression tasks. As an instance-based learning strategy, KNN operates on the premise that objects in close proximity to one another are likely to share similar outcomes. This non-parametric and lazy learning algorithm bases its predictions on the nearest neighbors within the training dataset, without necessitating a distinct training phase beforehand.\n",
        "\n",
        "### k-NN Algorithm\n",
        "\n",
        "The k-Nearest Neighbors algorithm can be summarized as follows:\n",
        "\n",
        "1. **Initialization:** It begins with a pre-labeled training dataset alongside a new, unlabeled point that requires classification or value prediction.\n",
        "\n",
        "2. **Distance Calculation:** The algorithm computes the distance between the new point and all points in the training dataset utilizing a specific distance metric, such as Euclidean distance, to gauge closeness.\n",
        "\n",
        "3. **Neighbor Selection:** It identifies the 'k' closest points (neighbors) to the new point based on the calculated distances.\n",
        "\n",
        "4. **Outcome Prediction:**\n",
        "    - In classification tasks, KNN assigns a class to the new point based on the most common class among its 'k' nearest neighbors.\n",
        "    \n",
        "    - For regression tasks, it predicts a value by averaging the values of the 'k' nearest neighbors.\n",
        "\n",
        "## Advantages and Disadvantages\n",
        "\n",
        "### Advantages\n",
        "\n",
        "1. **Simplicity**: The straightforwardness of KNN makes it easily understandable and implementable, serving as a powerful tool for analysts at all skill levels.\n",
        "\n",
        "2. **No Training Requirement**: Being a lazy learner, KNN is particularly suited for scenarios with dynamically changing datasets as it requires no explicit training phase.\n",
        "\n",
        "3. **Versatility**: KNN is adept at handling various types of data for classification, regression, and even anomaly detection.\n",
        "\n",
        "4. **Adaptability**: The algorithm is capable of adapting to different data distributions and capturing non-linear relationships.\n",
        "\n",
        "### Disadvantages\n",
        "\n",
        "1. **Computational Demand**: The need to compute distances to all training points for each prediction renders KNN computationally intensive, especially with large datasets.\n",
        "\n",
        "2. **Sensitivity to k**: The performance of KNN heavily depends on the chosen 'k' value, necessitating careful selection.\n",
        "\n",
        "3. **Feature Scaling Necessity**: Given KNN's reliance on distance calculations, appropriate scaling of features is crucial to avoid distortions.\n",
        "\n",
        "4. **Curse of Dimensionality**: KNN's efficiency may decrease in high-dimensional spaces due to sparse data distribution and increased computation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset Overview\n",
        "\n",
        "For our exploration, we pivot from the Swiss Roll dataset to the \"Life Expectancy of the World\" dataset. This rich dataset provides a comprehensive look at life expectancy metrics across various countries, serving as a foundation for understanding global health trends. Unlike the Swiss Roll's three-dimensional, continuous, and non-linear manifold characteristics, the Life Expectancy dataset offers a real-world scenario where life expectancy figures are tied to specific countries and their geographical locations.\n",
        "\n",
        "### Dataset Characteristics\n",
        "1. **Dimensionality:** The dataset spans multiple dimensions but focuses on life expectancy figures for overall, male, and female populations in each country.\n",
        "\n",
        "2. **Geographical Association:** Each country's data point is associated with a continent, introducing a categorical dimension that facilitates classification tasks.\n",
        "\n",
        "3. **Real-World Application:** The dataset's real-world applicability extends to public health analysis, demographic studies, and geographic classification tasks, offering a stark contrast to the Swiss Roll's abstract nature.\n",
        "\n",
        "4. **Analytical Potential:** The life expectancy figures allow for regression analysis to predict life expectancy based on various factors, while the country-to-continent mapping supports classification tasks.\n",
        "\n",
        "### Implementing K-Nearest Neighbors (KNN) with the Dataset\n",
        "\n",
        "The objective is to use KNN not for unfolding a manifold but for predicting a country's continent based on its life expectancy metrics, showcasing the algorithm's versatility beyond theoretical examples to tangible, impactful analyses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Load the Life Expectancy dataset\n",
        "data = pd.read_csv('Life_expectancy_dataset.csv')\n",
        "\n",
        "# Prepare the dataset\n",
        "features = data[['Overall Life', 'Male Life', 'Female Life']]\n",
        "target = data['Continent']\n",
        "\n",
        "# Encode categorical data and split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
        "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
        "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Encoding the 'Continent' column to transform it from categorical to numerical\u001b[39;00m\n\u001b[1;32m     11\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m---> 12\u001b[0m y_encoded \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContinent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Splitting the dataset\u001b[39;00m\n\u001b[1;32m     15\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverall Life\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMale Life\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFemale Life\u001b[39m\u001b[38;5;124m'\u001b[39m]], y_encoded, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Encoding the 'Continent' column to transform it from categorical to numerical\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(data['Continent'])\n",
        "\n",
        "# Splitting the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[['Overall Life', 'Male Life', 'Female Life']], y_encoded, test_size=0.3, random_state=42)\n",
        "\n",
        "# Scaling the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# K-Nearest Neighbors model\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Making predictions and evaluating the model\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "print('Classification Report:\\n', classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
        "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Visualization - Please adjust or replace this part as it's conceptual and may not directly apply without adjustments\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.title('Life Expectancy Data Classification with KNN')\n",
        "plt.scatter(X_test_scaled[:, 0], X_test_scaled[:, 1], c=y_pred, cmap='viridis', marker='o', edgecolor='k', s=20, alpha=0.5)\n",
        "plt.xlabel('Scaled Overall Life Expectancy')\n",
        "plt.ylabel('Scaled Male Life Expectancy')\n",
        "plt.colorbar(label='Continent', ticks=range(len(label_encoder.classes_)), format=plt.FuncFormatter(lambda val, loc: label_encoder.classes_[val]))\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
